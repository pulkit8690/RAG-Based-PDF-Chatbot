# ğŸ“ RAG-Based PDF Chatbot Using LLAMA3.2

This project implements a **Retrieval-Augmented Generation (RAG)** model using the **LLAMA3.2** large language model (LLM) to enable conversational interactions with PDFs. It maintains user chat history in a JSON file for personalized responses. The system retrieves relevant document chunks using **FAISS** vector search and **HuggingFace embeddings**.

---

## ğŸš€ Features
âœ… **Chat with PDFs** â€“ The chatbot retrieves answers from uploaded PDFs using RAG.  
âœ… **Persistent User History** â€“ Stores chat history in a JSON file to maintain session continuity.  
âœ… **Efficient Search with FAISS** â€“ Uses **FAISS (Facebook AI Similarity Search)** for document retrieval.  
âœ… **LLAMA3.2 for Response Generation** â€“ Utilizes **Ollama LLM** for generating responses.  
âœ… **GPU Acceleration** â€“ Automatically detects and uses GPU if available for faster processing.  

---

## ğŸ“‚ Project Structure

```
ğŸ“‚ RAG-Based-PDF-Chatbot/
â”‚-- ğŸ“„ main.py                    # Main script for chatbot interaction
â”‚-- ğŸ“‚ pdf/                       # Folder to store PDFs
â”‚-- ğŸ“‚ embeddings/                # FAISS vector storage
â”‚-- ğŸ“„ user_sessions.json         # User chat history JSON
â”‚-- ğŸ“„ requirements.txt           # Required dependencies
â”‚-- ğŸ“„ README.md                  # Project documentation
```

---

## ğŸ”§ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/pulkit8690/RAG-Based-PDF-Chatbot.git
cd RAG-Based-PDF-Chatbot
```

### 2ï¸âƒ£ Install Dependencies
Make sure you have **Python 3.8+** installed. Then, install the required dependencies:

```sh
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set Up the LLAMA3.2 Model
Ensure **Ollama** is installed and configure the model:

```python
from ollama import OllamaLLM
import torch

llm = OllamaLLM(
    model="llama3.2",
    temperature=0.5,
    device="cuda" if torch.cuda.is_available() else "cpu"
)
```

---

## ğŸ’¬ Usage

### Running the Chatbot
```sh
python main.py
```

### Interactive Chat
```sh
Enter your user ID (or 'exit' to terminate): user123
Enter your question, user123 (or 'quit' to switch users): What is the document about?
Response: The document discusses...
```

---

## ğŸ“Œ Notes
- If **no relevant information** is found in the uploaded PDFs, the chatbot will inform the user accordingly.
- The chatbot **only answers based on the uploaded documents**; it does not generate responses beyond the given context.
- User history is stored in **`user_sessions.json`** for context-aware conversations.

---

## ğŸ¤– Tech Stack

| Component      | Technology Used |
|---------------|----------------|
| **LLM**       | LLAMA3.2 via Ollama |
| **Embeddings** | sentence-transformers/all-MiniLM-L12-v2 |
| **Retrieval**  | FAISS Vector Database |
| **PDF Processing** | pdfplumber |
| **Backend**    | Python, LangChain |

---

## ğŸ›  Future Enhancements
- âœ… Implement **multi-document retrieval** for broader context.
- âœ… Add **web-based UI** using **Streamlit or Gradio**.
- âœ… Support **additional document formats (Word, TXT, etc.)**.
- âœ… Improve **response ranking with hybrid search** (BM25 + FAISS).

---

## ğŸ“œ License
This project is **open-source** and available under the [MIT License](LICENSE).

---

### ğŸŒŸ Contributions Welcome!
Feel free to **fork, contribute, or suggest improvements** via pull requests!

ğŸš€ **Happy Coding!**
```
